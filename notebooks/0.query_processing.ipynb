{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5e40cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import term_hiearchy\n",
    "import re\n",
    "import tqdm.notebook\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028a46d8",
   "metadata": {},
   "source": [
    "# Key term hit processing\n",
    "\n",
    "Parse, clean, and use hierarchy to process overlapping hits for regular expressions developed from qualitative glossary.\n",
    "\n",
    "\n",
    "## Data Description\n",
    "\n",
    "Parse dataframes generated by `generate_datasets_hierarchy.py -i 2021_04_15_scrape/2021_04_15_inceldom_discussion_scrape/complete_submissions_index.txt`\n",
    "These scripts take the scraped forum text data and search forum text using a set of regular expressions.\n",
    "\n",
    "- `2021_04_15_scrape/2021_04_15_inceldom_discussion_scrape/hierarchy_query_data.tsv.gz`: contains all hits to search terms in the qualitative glossary and encoded in `generate_datasets.py`\n",
    "\n",
    "- `2021_04_15_scrape/2021_04_15_inceldom_discussion_scrape/hierarchy_user_data.tsv.gz`: contains a database of all the users\n",
    "\n",
    "- `2021_04_15_scrape/2021_04_15_inceldom_discussion_scrape/hierarchy_users_per_thread.tsv.gz`: count of number of unique users in each thread\n",
    "\n",
    "- `term_hiearchy.hierarchy` contains the regular expressions used by `generate_datasets_hiearchy.py` in a series of OrderedDictionaries to retain priorities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15e19485",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_data = pd.read_csv('../2021_04_15_inceldom_discussion_scrape/hiearchy_query_data.tsv.gz', sep='\\t', lineterminator='\\n')\n",
    "\n",
    "# userdata will include more users than post data usernames as it includes users with deleted posts\n",
    "user_data = pd.read_csv('../2021_04_15_inceldom_discussion_scrape/hierarchy_user_data.tsv.gz', sep='\\t', lineterminator='\\n')\n",
    "user_data = user_data.sort_values(['username', 'number_of_posts'], ascending=False).drop_duplicates(subset=[\"username\"], keep=\"first\")\n",
    "post_data = pd.read_csv('../2021_04_15_inceldom_discussion_scrape/hierarchy_post_data.tsv.gz', sep='\\t', lineterminator='\\n')\n",
    "\n",
    "term_hiearchy_dict = term_hiearchy.hierarchy\n",
    "\n",
    "# build a dictionary of term priorities\n",
    "term_priorities = []\n",
    "ix = 0\n",
    "for term_category, terms in term_hiearchy_dict.items():\n",
    "    for term in term_hiearchy_dict[term_category]:\n",
    "        term_priorities.append((term, ix))\n",
    "        ix+=1\n",
    "\n",
    "term_priorities = OrderedDict(term_priorities)\n",
    "\n",
    "query_data['term_priority'] = query_data['query_term'].apply(lambda x: term_priorities[x])\n",
    "# filter out "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0163802c",
   "metadata": {},
   "source": [
    "Now we need to clean-up some false positive hits to \"JAP\" as part of the words \"japan\" and \"japanese\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4319564",
   "metadata": {},
   "outputs": [],
   "source": [
    "jap_fp = query_data[(query_data['query_term'] == 'JAP') & (query_data['query_word_after_match'].str.lower().isin(['an', 'anese', 'cel']))].index\n",
    "query_data = query_data.drop(jap_fp)\n",
    "\n",
    "jb_fp = query_data[(query_data['query_term'] == 'JB') & ((query_data['query_word_after_match'].str.len() == 1) | query_data['query_word_after_match'].str.lower().str.contains('wmax'))].index\n",
    "query_data = query_data.drop(jb_fp)\n",
    "\n",
    "co_fp = query_data[query_data['query_term'] == 'CO'].index\n",
    "query_data = query_data.drop(co_fp)\n",
    "\n",
    "trans_fp = query_data[(query_data['query_term'] == 'trans') & \\\n",
    "    (~query_data['query_word_after_match'].str.lower().isin(['sexuals', 'exual', 'sexual', 'phobia', 'men', 'man', 'rights', 'sexualism', 'exualism', 'vestites', 'sexuality', 'exuality', 'cels']))].index\n",
    "query_data = query_data.drop(trans_fp)\n",
    "\n",
    "hole_fp = query_data[(query_data['query_term'] == 'hole') & (~query_data['query_sentence'].str.contains(' hole '))].index\n",
    "query_data = query_data.drop(hole_fp)\n",
    "\n",
    "puta_fp = query_data[(query_data['query_term'] == 'puta') & (~query_data['query_sentence'].str.contains(' puta'))].index\n",
    "query_data = query_data.drop(puta_fp)\n",
    "\n",
    "bim_fp = query_data[(query_data['query_term'] == 'bim') & (~query_data['query_word_after_match'].str.lower().str.startswith('b', na=False))].index\n",
    "query_data = query_data.drop(bim_fp)\n",
    "\n",
    "gash_fp = query_data[(query_data['query_term'] == 'gash') & (query_data['query_word_after_match'].str.lower() == 'i')].index\n",
    "query_data = query_data.drop(gash_fp)\n",
    "\n",
    "skirt_fp = query_data[(query_data['query_term'] == 'skirt')].index\n",
    "query_data = query_data.drop(skirt_fp)\n",
    "\n",
    "scag_fp = query_data[(query_data['query_term'] == 'scag') & (~query_data['query_tidied_match'].str.contains('skag'))].index\n",
    "query_data = query_data.drop(scag_fp)\n",
    "\n",
    "pj_fp = query_data[(query_data['query_term'] == 'PJ')].index\n",
    "query_data = query_data.drop(pj_fp)\n",
    "\n",
    "lez_fp = query_data[(query_data['query_term'] == 'lez') & (~query_data['query_sentence'].str.lower().str.contains(' lez'))].index\n",
    "query_data = query_data.drop(lez_fp)\n",
    "\n",
    "gasher_fp = query_data[(query_data['query_term'] == 'gasher')].index\n",
    "query_data = query_data.drop(gasher_fp)\n",
    "\n",
    "hog_fp = query_data[(query_data['query_term'] == 'hog') & (~query_data['query_sentence'].str.lower().str.contains(' hog'))].index\n",
    "query_data = query_data.drop(hog_fp)\n",
    "\n",
    "hogwash_fp = query_data[(query_data['query_term'] == 'hog') & (query_data['query_word_after_match'] == 'wash')].index\n",
    "query_data = query_data.drop(hogwash_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36eee5f",
   "metadata": {},
   "source": [
    "Then we need to tidy up the terms defined as \"Racist Misogyny\" if followed by another term lower in the term hierarchy. We will do this by evaluating the neighbouring words using the regular expressions and if they hit then renaming the category to \"Racist Misogyny\" otherwise we leave it as is 'Racist Misogyny (if followed by other term)'.  After this runs we can drop all the remaining \"'Racist Misogyny (if followed by other term)'\" as this indicates they didn't have a neighbouring word that hit one of the regular expressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e28863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tidy up racist misogyny terms that aren't definitely racist misogyny (i.e., not follow by another term)\n",
    "def check_neighbouring_words(row):\n",
    "    if row['query_category'] != 'Racist Misogyny (if followed by other term)':\n",
    "        return row\n",
    "    \n",
    "    neighour = True\n",
    "    for term_category, terms in term_hiearchy_dict.items():\n",
    "        for term, term_regex in term_hiearchy_dict[term_category].items():\n",
    "            if not pd.isna(row['query_word_before_match']):\n",
    "                if re.match(term_regex, row['query_word_before_match']):\n",
    "                    row['query_category'] = 'Racist Misogyny'\n",
    "                    return row\n",
    "\n",
    "            if not pd.isna(row['query_word_after_match']):\n",
    "                if re.match(term_regex, row['query_word_after_match']):\n",
    "                    row['query_category'] = 'Racist Misogyny'\n",
    "                    return row  \n",
    "    return row\n",
    "\n",
    "query_data = query_data.apply(check_neighbouring_words, axis=1)\n",
    "# drop any remaining \"Racist Misogyny (if followed by other term)\" because if its still there after\n",
    "# checking for neighbouring words then it isn't valid\n",
    "query_data = query_data[query_data['query_category'] != 'Racist Misogyny (if followed by other term)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80abc885",
   "metadata": {},
   "source": [
    "Then we need to look at hits neighbouring each other and keep the term with the highest priority (from the term hierachy dictionaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30e3b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply hierarchy\n",
    "indices_to_remove = set()\n",
    "\n",
    "# for each thread get all the hits from that thread\n",
    "for group, hits_in_same_sentence in query_data.groupby(['thread_url', 'post_position', 'sentence_position']):  \n",
    "    if hits_in_same_sentence.shape[0] > 1:\n",
    "        # check if any of them overlap if they do delete the overlapping ones based on term priority\n",
    "        for hit_ix, hit in hits_in_same_sentence.sort_values('word_position').iterrows():\n",
    "        \n",
    "            adjacent_hits = hits_in_same_sentence[hits_in_same_sentence['word_position'].between(hit['word_position'] -1, \n",
    "                                                                                                 hit['word_position'] + 1)]\n",
    "            #adjacent_hits = adjacent_hits.drop(hit_ix)\n",
    "            if adjacent_hits.shape[0] > 1:\n",
    "                # take the top priority hit\n",
    "                adjacent_hits = adjacent_hits.sort_values('term_priority')\n",
    "                for ix in adjacent_hits.iloc[1:].index:\n",
    "                    indices_to_remove.add(ix)\n",
    "\n",
    "query_data = query_data.drop(indices_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9406979",
   "metadata": {},
   "source": [
    "Finally we can save the processed query data for quantiative analysis in notebook 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16664c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_data.to_csv('../2021_04_15_inceldom_discussion_scrape/hierarchy_query_data_PROCESSED.tsv.gz', compression='gzip', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
